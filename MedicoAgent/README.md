# ğŸ©º MedicoAgent â€” ReAct RAG Clinical Assistant (Ollama + FAISS + LangChain)

![Python](https://img.shields.io/badge/Python-3.10+-blue?logo=python)
![Streamlit](https://img.shields.io/badge/Streamlit-App-red?logo=streamlit)
![LangChain](https://img.shields.io/badge/LangChain-Enabled-green?logo=chainlink)
![FAISS](https://img.shields.io/badge/FAISS-RAG_VectorDB-orange)

---

## ğŸ§  Overview
**MedicoAgent** is an educational AI clinical assistant built using **Streamlit**, **LangChain**, **FAISS**, and **Ollama (Llama3.1)**.

It operates on a **ReAct (Reason + Act)** pipeline â€” combining **retrieval-augmented generation (RAG)** with **tool usage** for physiological calculations such as:
- Body Mass Index (BMI)
- Mean Arterial Pressure (MAP)
- Anion Gap

> âš ï¸ **Disclaimer:**  
> This system is for **educational and research use only.** It does **not provide medical advice, diagnosis, or treatment.**

---

## âš™ï¸ Features

| Feature | Description |
|----------|--------------|
| ğŸ§© **RAG Integration** | FAISS-based local retrieval from structured corpus |
| ğŸ§® **Medical Tools** | Built-in BMI, MAP, and Anion Gap calculators |
| ğŸ§  **Local LLM Support** | Uses Ollama with Llama3.1 (can replace with local or cloud models) |
| ğŸ’¬ **ReAct Reasoning** | Multi-step reasoning with tool usage and context retrieval |
| ğŸ¨ **Custom UI** | Dark mode Streamlit app with ChatGPT-style centered layout |
| ğŸ§¾ **Safety Layer** | Built-in educational disclaimer and structured system prompts |

---

## ğŸ—ï¸ Architecture


---

### **3ï¸âƒ£ Optional: Use Mermaid**
GitHub supports Mermaid for diagrams, which looks nicer and scales better:
```mermaid
flowchart TD
    A["User Interface - Streamlit"] --> B["ReAct Controller - LangChain"]
    B --> C["Tools - Python"]
    C --> D["FAISS RAG Retriever"]
    D --> E["Local LLM - Ollama llama3.1"]
```

## ğŸ§° Installation
1ï¸âƒ£ **Create and Activate Virtual Environment**
```bash 
conda create -n medicoagent python=3.10 -y
conda activate medicoagent
```
2ï¸âƒ£ **Install Dependencies**
```bash

pip install -r requirements.txt

```
3ï¸âƒ£**Create and Activate Virtual Environment**
```bash
conda create -n medicoagent python=3.10 -y
conda activate medicoagent
```
4ï¸âƒ£  **Install Dependencies**
```bash
pip install -r requirements.txt
Example requirements.txt:
streamlit
langchain
langchain-community
langchain-huggingface
faiss-cpu
pydantic
requests
python-dotenv
```
5ï¸âƒ£ **Setup .env File**
```bash
Create a .env file in the project root:
LANGSMITH_API_KEY=your_langsmith_api_key
```
6ï¸âƒ£ **Run Ollama (for Local LLM)**
```bash
Download Ollama and pull the model:
ollama pull llama3.1
Then start Ollama in the background (default port 11434)
```
##ğŸš€ **Run the Streamlit App**
```bash 
streamlit run app.py
Open http://localhost:8501 in your browser.
```

##ğŸ§ª **Example Queries**
```bash
â€œA patient has SBP 120 mmHg and DBP 80 mmHg. Calculate MAP.â€
â€œIf sodium is 140, chloride 104, and bicarbonate 24, whatâ€™s the anion gap?â€
â€œExplain tissue hypoxia and its effects.â€
```
##ğŸ“Š **Output Format (Structured)**
```bash
Red Flags: Immediate clinical alerts.
Key Missing Questions: Up to 4 clarifications.
Calculated Parameters: (e.g., BMI, MAP).
Hypotheses (Educational Only): Possible conditions.
Next-Step Considerations: Learning takeaways.
Citations: Corpus references.
Safety Note: Educational disclaimer.
```


